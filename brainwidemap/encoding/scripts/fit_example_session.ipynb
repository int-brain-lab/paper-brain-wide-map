{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting encoding models to a single session and probe insertion\n",
    "\n",
    "This notebook aims to introduce you to the methodology behind the analyses of single-unit encoding models. Beginning with loading in session and spiking data, we will generate a design matrix for that data and then fit the neurons within using said matrix. This script will fit a regularized linear model, and not a poisson model, as that is what is used in the paper.\n",
    "\n",
    "## Loading in data\n",
    "\n",
    "We begin by first loading in the trials dataframe, spikes, and cluster information (such as QC metrics and brain region labels) for a given session ID and probe ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import brainbox.io.one as bbone\n",
    "from iblutil.util import Bunch\n",
    "from one.api import ONE\n",
    "from brainwidemap.bwm_loading import load_trials_and_mask\n",
    "from brainwidemap.encoding.utils import load_trials_df\n",
    "\n",
    "\n",
    "def load_regressors(session_id,\n",
    "                    pid,\n",
    "                    t_before=0.,\n",
    "                    t_after=0.,\n",
    "                    binwidth=0.02,\n",
    "                    abswheel=False,\n",
    "                    clu_criteria='bwm',\n",
    "                    one=None):\n",
    "    \"\"\"\n",
    "    Load in regressors for given session and probe. Returns a dictionary with the following keys:\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    session_id : str\n",
    "        EID of the session to load\n",
    "    pid : str\n",
    "        Probe ID to load associated with the session\n",
    "    t_before : float, optional\n",
    "        Time before stimulus onset to include in output trial_start column of df, by default 0.\n",
    "    t_after : float, optional\n",
    "        Time after feedback to include in output trial_end column of df, by default 0.\n",
    "    binwidth : float, optional\n",
    "        Binwidth for wheel signal. Needs to match that of GLM, by default 0.02\n",
    "    abswheel : bool, optional\n",
    "        Load in wheel speed instead of velocity, by default False\n",
    "    ret_qc : bool, optional\n",
    "        Whether to recompute cluster metrics and return a full dataframe of the result,\n",
    "        by default False\n",
    "    clu_criteria : str, optional\n",
    "        Criteria for saving clusters, 'all' for all units, 'bwm' for criteria matching that of\n",
    "        brain-wide map (all metrics passing). No others supported for now., by default 'bwm'\n",
    "    one : ONE, optional\n",
    "        Instance of ONE, by default None\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    trialsdf, spk_times, spk_clu, clu_regions, clu_qc, clu_df, clu_qc (optional)\n",
    "        Output regressors for GLM\n",
    "    \"\"\"\n",
    "    one = ONE() if one is None else one\n",
    "\n",
    "    _, mask = load_trials_and_mask(one=one, eid=session_id)\n",
    "    mask = mask.index[np.nonzero(mask.values)]\n",
    "    trialsdf = load_trials_df(\n",
    "        session_id,\n",
    "        t_before=t_before,\n",
    "        t_after=t_after,\n",
    "        wheel_binsize=binwidth,\n",
    "        ret_abswheel=abswheel,\n",
    "        ret_wheel=not abswheel,\n",
    "        addtl_types=['firstMovement_times'],\n",
    "        one=one,\n",
    "        trials_mask=mask,\n",
    "    )\n",
    "\n",
    "    clusters = {}\n",
    "    ssl = bbone.SpikeSortingLoader(one=one, pid=pid)\n",
    "    origspikes, tmpclu, channels = ssl.load_spike_sorting()\n",
    "    if 'metrics' not in tmpclu:\n",
    "        tmpclu['metrics'] = np.ones(tmpclu['channels'].size)\n",
    "    clusters[pid] = ssl.merge_clusters(origspikes, tmpclu, channels)\n",
    "    clu_df = pd.DataFrame(clusters[pid]).set_index(['cluster_id'])\n",
    "    clu_df['pid'] = pid\n",
    "\n",
    "    if clu_criteria == 'bwm':\n",
    "        keepclu = clu_df.index[clu_df.label == 1]\n",
    "    elif clu_criteria == 'all':\n",
    "        keepclu = clu_df.index\n",
    "    else:\n",
    "        raise ValueError(\"clu_criteria must be 'bwm' or 'all'\")\n",
    "\n",
    "    clu_df = clu_df.loc[keepclu]\n",
    "    keepmask = np.isin(origspikes.clusters, keepclu)\n",
    "    spikes = Bunch({k: v[keepmask] for k, v in origspikes.items()})\n",
    "    sortinds = np.argsort(spikes.times)\n",
    "    spk_times = spikes.times[sortinds]\n",
    "    spk_clu = spikes.clusters[sortinds]\n",
    "    clu_regions = clusters[pid].acronym\n",
    "    return trialsdf, spk_times, spk_clu, clu_regions, clu_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iblenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.15 | packaged by conda-forge | (main, Nov 22 2022, 15:55:03) \n[GCC 10.4.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "babb0c57ea6d35f3ae02a6794ae8d0c3372548fefa8e0b553d5e4910e6664ad8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
